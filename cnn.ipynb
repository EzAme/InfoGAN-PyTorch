{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "load_path = 'checkpoint/model_final_HGD'\n",
    "\n",
    "from models.cnnmodel import Net\n",
    "from models.hgd_model2 import Generator\n",
    "from HandGestureDataset import HandGestureDataSet as HGD\n",
    "from utils import HGDThreshold as HGDT\n",
    "from utils import noise_sample\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Krishanu/Desktop/Education/Programcodes/Python/DeepLearning/Project/leapGestRecog/\"\n",
    "training = HGD(root = path, train = True,\n",
    "    transform = T.Compose([\n",
    "                T.ToPILImage(),\n",
    "              \n",
    "                # T.RandomHorizontalFlip(p=0.5),\n",
    "                T.Resize((240,240)),\n",
    "                # T.CenterCrop((190,180)),\n",
    "                T.RandomCrop((180,180)),\n",
    "                T.Resize((64,64)),\n",
    "                T.RandomRotation(20),\n",
    "                T.ToTensor(), \n",
    "                HGDT(55.0/256.0),\n",
    "                # T.Normalize(100/256.0,1),\n",
    "                # T.RandomAdjustSharpness(sharpness_factor = 4,p=0.5),\n",
    "                # T.RandomAutocontrast(p=1),\n",
    "\n",
    "                ])\n",
    "            )\n",
    "validation = HGD(root = path, train= False,\n",
    "    transform = T.Compose([\n",
    "                T.ToPILImage(),\n",
    "              \n",
    "                # T.RandomHorizontalFlip(p=0.5),\n",
    "                T.Resize((240,240)),\n",
    "                # T.CenterCrop((190,180)),\n",
    "                T.RandomCrop((180,180)),\n",
    "                T.Resize((64,64)),\n",
    "                T.RandomRotation(20),\n",
    "                T.ToTensor(), \n",
    "                HGDT(55.0/256.0),\n",
    "                # T.Normalize(100/256.0,1),\n",
    "                # T.RandomAdjustSharpness(sharpness_factor = 4,p=0.5),\n",
    "                # T.RandomAutocontrast(p=1),\n",
    "\n",
    "                ])\n",
    "            )\n",
    "\n",
    "batch_size = 32\n",
    "train_batch = DataLoader(training, batch_size=batch_size, shuffle=True, num_workers= 8)\n",
    "val_batch = DataLoader(validation, batch_size=batch_size, shuffle=True, num_workers= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, training_data, device, optimizer, epoch, netG, use_gen=True, use_train = True):\n",
    "\n",
    "    \"\"\"\n",
    "    This is the main function for training a deep neural network.\n",
    "    Inputs:\n",
    "    {\n",
    "    model: The Neural network\n",
    "    training_data: Training data with labels\n",
    "    device: Physical location of where data is stored (\"CPU\" or \"GPU\")\n",
    "    optimizer: Optimizer Function e.g. torch.optim.adam\n",
    "    scheduler: The type of scheduling for modifying the learning rate\n",
    "    num_epochs: number of iterations to train on the data\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    model.train() #Set the model to \"training\" mode and compute gradients\n",
    "    if use_train:\n",
    "        print('-'*25)\n",
    "        print('Training using Training Data')\n",
    "        print('-'*25)\n",
    "        for batch_idx, (image, label) in enumerate(training_data):\n",
    "            image, label = image.to(device), label.to(device) # place the input data into gpu ram or cpu ram\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            loss = nn.functional.cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                total_loss += loss.sum().item()\n",
    "                pred = output.argmax(dim =1 , keepdim=True)\n",
    "                correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(image), len(training_data.dataset),\n",
    "                    100. * batch_idx / len(training_data), loss.item()))\n",
    "\n",
    "    total_loss_gen = 0\n",
    "    correct_gen =0\n",
    "    if use_gen:\n",
    "        print('-'*25)\n",
    "        print('Training using Generator Data')\n",
    "        print('-'*25)\n",
    "        for i, _ in enumerate(training_data):\n",
    "            noise,idx,_,con = noise_sample(1,10,4,256,batch_size,device)\n",
    "            target = torch.LongTensor(idx).to(device)\n",
    "            image = netG(noise.squeeze((2,3)),target.view(-1,1),con)\n",
    "            label = torch.LongTensor(idx).to(device).squeeze(0)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            loss = nn.functional.cross_entropy(output, label)*0.9**epoch\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                total_loss_gen += loss.sum().item()\n",
    "                pred = output.argmax(dim =1 , keepdim=True)\n",
    "                correct_gen += pred.eq(label.view_as(pred)).sum().item()\n",
    "            if i % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, i * len(image), len(training_data.dataset),\n",
    "                    100. * i / len(training_data), loss.item()))\n",
    "    if use_gen and use_train:\n",
    "        print('\\nTotal Training Set: \\n\\tAverage loss: {:.4f}\\n\\tAccuracy: {}/{} ({}%)'.format(\n",
    "            (total_loss+total_loss_gen)/len(training_data.dataset)/2,\n",
    "            correct+correct_gen,\n",
    "            len(training_data.dataset)*2,\n",
    "            100*(correct+correct_gen)/len(training_data.dataset)/2))\n",
    "    if use_train:\n",
    "        print('\\nTraining Set: \\n\\tAverage loss: {:.4f}\\n\\tAccuracy: {}/{} ({}%)'.format(\n",
    "        (total_loss)/len(training_data.dataset),\n",
    "        correct,\n",
    "        len(training_data.dataset),\n",
    "        100*(correct)/len(training_data.dataset)))\n",
    "    if use_gen:\n",
    "        print('\\nGenerator Set: \\n\\tAverage loss: {:.4f}\\n\\tAccuracy: {}/{} ({}%)'.format(\n",
    "            (total_loss_gen)/len(training_data.dataset),\n",
    "            correct_gen,\n",
    "            len(training_data.dataset),\n",
    "            100*correct_gen/len(training_data.dataset)))\n",
    "    \n",
    "    # wandb.watch(model)\n",
    "    # wandb.log({'Training Loss':total_loss/len(training_data.dataset),'Training Accuracy':correct/len(training_data.dataset)},commit = False)\n",
    "\n",
    "\n",
    "\n",
    "def validate_model(model, test_data,scheduler, device):\n",
    "\n",
    "    \"\"\"\n",
    "    This is the function to monitor a deep neural network's performance on validation data. Sends images and predictions to wandb\n",
    "    \n",
    "    Inputs:\n",
    "    {\n",
    "    model: The Neural network\n",
    "    test_data: test data with labels\n",
    "    device: Physical location of where data is stored (CPU or GPU)\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval() #Set the model to \"evaluation\" mode and NOT compute gradients\n",
    "    total_loss = 0\n",
    "    correct = 0 \n",
    "    with torch.no_grad(): #Prevent pytorch from computing gradients\n",
    "        for image, label in test_data:\n",
    "            image, label = image.to(device), label.to(device) # place the input data into gpu ram or cpu ram\n",
    "            output = model(image)\n",
    "            total_loss = nn.functional.cross_entropy(output, label, reduction = 'sum').item()\n",
    "            pred = output.argmax(dim =1 , keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "    total_loss /= len(test_data.dataset)\n",
    "    scheduler.step(total_loss)\n",
    "    print('Test set: \\n\\tAverage loss: {:.4f}\\n\\tAccuracy: {}/{} ({}%)\\n'.format(\n",
    "            total_loss,\n",
    "            correct, \n",
    "            len(test_data.dataset),\n",
    "            100. * correct /len(test_data.dataset)))\n",
    "    \n",
    "    \n",
    "    # wandb.log({'Validation Loss':total_loss,'Validation Accuracy':correct/len(test_data.dataset)},commit = False)\n",
    "            \n",
    "            \n",
    "    #######################################################################################################\n",
    "    # wandb_iter = iter(test_data)\n",
    "    # wandb_i,wandb_l = wandb_iter.next()\n",
    "    # with torch.no_grad():\n",
    "    #     wandb.log({'Predictions':[wandb.Image(wandb_i[i],caption = f\"Label: {int(wandb_l[i])}, Prediction: {int(torch.argmax(model(wandb_i[i].unsqueeze(0).to(device))))}\") for i in range(10)] },commit = True)\n",
    "    #######################################################################################################\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Determines if the model will be trained on gpu or cpu\n",
    "#------Initialize Generator------\n",
    "netG = Generator().to(device)\n",
    "state_dict = torch.load(load_path)\n",
    "params = state_dict['params']\n",
    "netG.load_state_dict(state_dict['netG'])\n",
    "use_gen = True\n",
    "\n",
    "#-----Initialize CNN model-----\n",
    "learning_rate = 6e-5\n",
    "num_epochs = 10 # Number of times to look over the data.\n",
    "model_ft = Net() # Initialize the model\n",
    "model_ft = model_ft.to(device) # Send the model to Ram or GPU Ram\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate, weight_decay = 7e-5) # Initialize optimizer\n",
    "exp_lr_scheduler = lr_sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft,patience=3,threshold=0.01) #initialize scheduler. Every (1) epoch, reduce the learning rate by a factor of 0.7\n",
    "use_train = True\n",
    "\n",
    "print(len(train_batch.dataset))\n",
    "print(\"Learning Rate: \",learning_rate,\"\\nBatch Size: \", batch_size)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "Learning Rate:  6e-05 \n",
      "Batch Size:  32\n",
      "cuda\n",
      "Train Epoch: 0 [0/16000 (0%)]\tLoss: 2.299947\n",
      "Train Epoch: 0 [3200/16000 (20%)]\tLoss: 2.149292\n",
      "Train Epoch: 0 [6400/16000 (40%)]\tLoss: 1.908826\n",
      "Train Epoch: 0 [9600/16000 (60%)]\tLoss: 1.604508\n",
      "Train Epoch: 0 [12800/16000 (80%)]\tLoss: 1.454826\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 0 [0/16000 (0%)]\tLoss: 1.919851\n",
      "Train Epoch: 0 [3200/16000 (20%)]\tLoss: 1.674396\n",
      "Train Epoch: 0 [6400/16000 (40%)]\tLoss: 1.767294\n",
      "Train Epoch: 0 [9600/16000 (60%)]\tLoss: 1.313272\n",
      "Train Epoch: 0 [12800/16000 (80%)]\tLoss: 1.500361\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0520\n",
      "\tAccuracy: 13069/32000 (40.840625%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0147\n",
      "\tAccuracy: 2319/4000 (57.975%)\n",
      "\n",
      "Train Epoch: 1 [0/16000 (0%)]\tLoss: 1.317767\n",
      "Train Epoch: 1 [3200/16000 (20%)]\tLoss: 0.842776\n",
      "Train Epoch: 1 [6400/16000 (40%)]\tLoss: 0.798645\n",
      "Train Epoch: 1 [9600/16000 (60%)]\tLoss: 0.572954\n",
      "Train Epoch: 1 [12800/16000 (80%)]\tLoss: 0.651244\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 1 [0/16000 (0%)]\tLoss: 1.539023\n",
      "Train Epoch: 1 [3200/16000 (20%)]\tLoss: 1.074411\n",
      "Train Epoch: 1 [6400/16000 (40%)]\tLoss: 1.005913\n",
      "Train Epoch: 1 [9600/16000 (60%)]\tLoss: 1.194539\n",
      "Train Epoch: 1 [12800/16000 (80%)]\tLoss: 1.106136\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0286\n",
      "\tAccuracy: 21235/32000 (66.359375%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0091\n",
      "\tAccuracy: 2802/4000 (70.05%)\n",
      "\n",
      "Train Epoch: 2 [0/16000 (0%)]\tLoss: 0.749362\n",
      "Train Epoch: 2 [3200/16000 (20%)]\tLoss: 0.513341\n",
      "Train Epoch: 2 [6400/16000 (40%)]\tLoss: 0.326920\n",
      "Train Epoch: 2 [9600/16000 (60%)]\tLoss: 0.254628\n",
      "Train Epoch: 2 [12800/16000 (80%)]\tLoss: 0.364478\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 2 [0/16000 (0%)]\tLoss: 1.319559\n",
      "Train Epoch: 2 [3200/16000 (20%)]\tLoss: 1.044305\n",
      "Train Epoch: 2 [6400/16000 (40%)]\tLoss: 0.737102\n",
      "Train Epoch: 2 [9600/16000 (60%)]\tLoss: 1.766364\n",
      "Train Epoch: 2 [12800/16000 (80%)]\tLoss: 0.759559\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0209\n",
      "\tAccuracy: 23497/32000 (73.428125%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0063\n",
      "\tAccuracy: 2915/4000 (72.875%)\n",
      "\n",
      "Train Epoch: 3 [0/16000 (0%)]\tLoss: 0.748654\n",
      "Train Epoch: 3 [3200/16000 (20%)]\tLoss: 0.292870\n",
      "Train Epoch: 3 [6400/16000 (40%)]\tLoss: 0.376516\n",
      "Train Epoch: 3 [9600/16000 (60%)]\tLoss: 0.327758\n",
      "Train Epoch: 3 [12800/16000 (80%)]\tLoss: 0.297082\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 3 [0/16000 (0%)]\tLoss: 1.393563\n",
      "Train Epoch: 3 [3200/16000 (20%)]\tLoss: 0.597497\n",
      "Train Epoch: 3 [6400/16000 (40%)]\tLoss: 0.986147\n",
      "Train Epoch: 3 [9600/16000 (60%)]\tLoss: 0.726916\n",
      "Train Epoch: 3 [12800/16000 (80%)]\tLoss: 0.756196\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0178\n",
      "\tAccuracy: 24202/32000 (75.63125%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0047\n",
      "\tAccuracy: 2780/4000 (69.5%)\n",
      "\n",
      "Train Epoch: 4 [0/16000 (0%)]\tLoss: 0.604509\n",
      "Train Epoch: 4 [3200/16000 (20%)]\tLoss: 0.374358\n",
      "Train Epoch: 4 [6400/16000 (40%)]\tLoss: 0.165484\n",
      "Train Epoch: 4 [9600/16000 (60%)]\tLoss: 0.408033\n",
      "Train Epoch: 4 [12800/16000 (80%)]\tLoss: 0.200130\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 4 [0/16000 (0%)]\tLoss: 1.059341\n",
      "Train Epoch: 4 [3200/16000 (20%)]\tLoss: 0.546221\n",
      "Train Epoch: 4 [6400/16000 (40%)]\tLoss: 0.642613\n",
      "Train Epoch: 4 [9600/16000 (60%)]\tLoss: 0.552932\n",
      "Train Epoch: 4 [12800/16000 (80%)]\tLoss: 0.681645\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0148\n",
      "\tAccuracy: 24811/32000 (77.534375%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0052\n",
      "\tAccuracy: 2885/4000 (72.125%)\n",
      "\n",
      "Train Epoch: 5 [0/16000 (0%)]\tLoss: 0.738615\n",
      "Train Epoch: 5 [3200/16000 (20%)]\tLoss: 0.201461\n",
      "Train Epoch: 5 [6400/16000 (40%)]\tLoss: 0.142742\n",
      "Train Epoch: 5 [9600/16000 (60%)]\tLoss: 0.148006\n",
      "Train Epoch: 5 [12800/16000 (80%)]\tLoss: 0.122914\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 5 [0/16000 (0%)]\tLoss: 1.220170\n",
      "Train Epoch: 5 [3200/16000 (20%)]\tLoss: 0.559248\n",
      "Train Epoch: 5 [6400/16000 (40%)]\tLoss: 0.399360\n",
      "Train Epoch: 5 [9600/16000 (60%)]\tLoss: 0.770580\n",
      "Train Epoch: 5 [12800/16000 (80%)]\tLoss: 1.120897\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0130\n",
      "\tAccuracy: 25070/32000 (78.34375%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0069\n",
      "\tAccuracy: 2950/4000 (73.75%)\n",
      "\n",
      "Train Epoch: 6 [0/16000 (0%)]\tLoss: 0.467354\n",
      "Train Epoch: 6 [3200/16000 (20%)]\tLoss: 0.189340\n",
      "Train Epoch: 6 [6400/16000 (40%)]\tLoss: 0.086490\n",
      "Train Epoch: 6 [9600/16000 (60%)]\tLoss: 0.111828\n",
      "Train Epoch: 6 [12800/16000 (80%)]\tLoss: 0.142140\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 6 [0/16000 (0%)]\tLoss: 0.595843\n",
      "Train Epoch: 6 [3200/16000 (20%)]\tLoss: 0.517884\n",
      "Train Epoch: 6 [6400/16000 (40%)]\tLoss: 0.319071\n",
      "Train Epoch: 6 [9600/16000 (60%)]\tLoss: 0.482707\n",
      "Train Epoch: 6 [12800/16000 (80%)]\tLoss: 0.340849\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0113\n",
      "\tAccuracy: 25468/32000 (79.5875%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0071\n",
      "\tAccuracy: 3064/4000 (76.6%)\n",
      "\n",
      "Train Epoch: 7 [0/16000 (0%)]\tLoss: 0.583720\n",
      "Train Epoch: 7 [3200/16000 (20%)]\tLoss: 0.151132\n",
      "Train Epoch: 7 [6400/16000 (40%)]\tLoss: 0.052173\n",
      "Train Epoch: 7 [9600/16000 (60%)]\tLoss: 0.081565\n",
      "Train Epoch: 7 [12800/16000 (80%)]\tLoss: 0.056607\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 7 [0/16000 (0%)]\tLoss: 0.943294\n",
      "Train Epoch: 7 [3200/16000 (20%)]\tLoss: 0.491888\n",
      "Train Epoch: 7 [6400/16000 (40%)]\tLoss: 0.596154\n",
      "Train Epoch: 7 [9600/16000 (60%)]\tLoss: 0.680283\n",
      "Train Epoch: 7 [12800/16000 (80%)]\tLoss: 0.360333\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0097\n",
      "\tAccuracy: 25712/32000 (80.35%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0066\n",
      "\tAccuracy: 3016/4000 (75.4%)\n",
      "\n",
      "Train Epoch: 8 [0/16000 (0%)]\tLoss: 0.652670\n",
      "Train Epoch: 8 [3200/16000 (20%)]\tLoss: 0.309376\n",
      "Train Epoch: 8 [6400/16000 (40%)]\tLoss: 0.286114\n",
      "Train Epoch: 8 [9600/16000 (60%)]\tLoss: 0.162129\n",
      "Train Epoch: 8 [12800/16000 (80%)]\tLoss: 0.223277\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 8 [0/16000 (0%)]\tLoss: 0.367302\n",
      "Train Epoch: 8 [3200/16000 (20%)]\tLoss: 0.516588\n",
      "Train Epoch: 8 [6400/16000 (40%)]\tLoss: 0.349935\n",
      "Train Epoch: 8 [9600/16000 (60%)]\tLoss: 0.305295\n",
      "Train Epoch: 8 [12800/16000 (80%)]\tLoss: 0.396632\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0101\n",
      "\tAccuracy: 25877/32000 (80.865625%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0041\n",
      "\tAccuracy: 3311/4000 (82.775%)\n",
      "\n",
      "Train Epoch: 9 [0/16000 (0%)]\tLoss: 0.364856\n",
      "Train Epoch: 9 [3200/16000 (20%)]\tLoss: 0.290071\n",
      "Train Epoch: 9 [6400/16000 (40%)]\tLoss: 0.198184\n",
      "Train Epoch: 9 [9600/16000 (60%)]\tLoss: 0.189927\n",
      "Train Epoch: 9 [12800/16000 (80%)]\tLoss: 0.084704\n",
      "-------------------------\n",
      "training using Generator Data\n",
      "-------------------------\n",
      "Train Epoch: 9 [0/16000 (0%)]\tLoss: 0.261001\n",
      "Train Epoch: 9 [3200/16000 (20%)]\tLoss: 0.673624\n",
      "Train Epoch: 9 [6400/16000 (40%)]\tLoss: 0.184767\n",
      "Train Epoch: 9 [9600/16000 (60%)]\tLoss: 0.483566\n",
      "Train Epoch: 9 [12800/16000 (80%)]\tLoss: 0.378546\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0085\n",
      "\tAccuracy: 26160/32000 (81.75%)\n",
      "Test set: \n",
      "\tAverage loss: 0.0066\n",
      "\tAccuracy: 3295/4000 (82.375%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################### WANDB Setup ###################\n",
    "# wandb.init(project = 'ECE6254'\n",
    "#         ,config = {'learning_rate':0.01, 'batch_size':64}\n",
    "#             )\n",
    "# config = wandb.config\n",
    "\n",
    "# batch_size_train = config.batch_size\n",
    "# batch_size_test = 1000\n",
    "# learning_rate = config.learning_rate\n",
    "####################################################\n",
    "\n",
    "##### Main Loop for Training ######\n",
    "for epoch in range(num_epochs):\n",
    "            train_model(model_ft,\n",
    "                        train_batch,\n",
    "                        device, \n",
    "                        optimizer_ft, \n",
    "                        epoch,netG, \n",
    "                        use_gen,\n",
    "                        use_train)\n",
    "            validate_model(model_ft,\n",
    "                        val_batch,\n",
    "                        exp_lr_scheduler,\n",
    "                        device) \n",
    "###################################                         \n",
    "\n",
    "#################################################\n",
    "# wandb.finish()\n",
    "#################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.2345e-01, -8.3329e-01,  2.2396e+00, -3.0226e+00,  7.7240e+00,\n",
      "         -6.0150e-01, -5.5547e+00, -3.0533e+00, -4.5437e+00,  1.6168e+00],\n",
      "        [-1.7345e+00, -1.3489e+00, -2.4272e+00,  1.3327e+00, -1.0535e+00,\n",
      "         -5.7577e-01, -4.4381e-01,  1.9520e+00,  5.2195e-02, -1.5884e+00],\n",
      "        [-6.2452e-01, -2.0242e+00, -2.0680e+00,  2.9012e+00, -1.9957e+00,\n",
      "         -1.3343e+00, -1.5106e+00,  1.7233e+00,  3.8747e+00, -1.0024e+00],\n",
      "        [ 6.7983e+00, -2.7966e+00,  7.2231e+00,  9.1057e+00,  1.6719e+00,\n",
      "          2.5638e+00, -1.0202e+01, -4.3600e+00, -2.5719e+00, -6.2671e+00],\n",
      "        [ 1.6845e+00,  2.6673e+00,  5.2903e+00,  9.9706e-01, -1.2042e+00,\n",
      "          7.6981e+00, -3.0185e-01, -3.8470e+00, -3.9364e+00, -4.0643e+00],\n",
      "        [-5.9152e+00,  6.5262e-01, -2.1303e+00,  1.4017e-01, -1.1732e+00,\n",
      "         -2.7610e-01, -4.3961e-01,  3.2714e+00,  3.0565e+00, -1.5829e+00],\n",
      "        [-1.2830e-01,  4.8337e-01, -6.7586e-02,  3.1900e-01,  3.8635e-01,\n",
      "          9.0439e-01, -3.0364e-01, -1.9497e+00, -2.0104e+00, -3.5343e-01],\n",
      "        [-2.0145e+00, -5.4946e+00, -1.2779e+00,  4.2054e+00, -1.7437e+00,\n",
      "         -4.6467e+00, -4.0289e+00,  4.6144e+00,  6.1443e+00, -1.1631e+00],\n",
      "        [ 5.5817e+00, -4.2658e+00,  5.4598e+00,  8.7521e+00,  1.3018e+00,\n",
      "          1.3336e+00, -1.0910e+01, -6.1408e+00, -1.1818e+00, -3.6363e+00],\n",
      "        [-5.3311e+00, -5.9501e-01, -3.2446e+00,  3.0029e-02, -1.4052e+00,\n",
      "         -3.1826e-01, -5.8719e-01,  4.2581e+00,  3.3356e+00, -1.4122e+00],\n",
      "        [ 3.1385e+00, -4.0585e+00,  9.0693e+00,  7.6606e+00,  5.7520e+00,\n",
      "          2.7500e+00, -1.4015e+01, -3.7115e+00, -1.6511e+00,  1.0522e+00],\n",
      "        [-1.5669e-01, -2.2192e-01,  1.4294e-01,  1.3757e+00, -1.7267e+00,\n",
      "          2.4936e+00,  4.2546e-01, -2.5881e+00,  2.8339e-01, -3.0548e+00],\n",
      "        [ 1.9457e+00,  1.6157e+00,  3.1930e+00, -7.8251e-01,  5.6066e+00,\n",
      "          2.6935e+00, -3.1480e+00, -5.6171e+00, -7.1346e+00, -7.9577e-03],\n",
      "        [ 7.4338e+00, -4.6890e-01,  1.0195e+00,  2.1777e+00, -2.9689e+00,\n",
      "          2.0532e+00,  1.4345e+00,  2.9077e-01, -4.6682e+00, -3.6875e+00],\n",
      "        [ 1.6124e-01, -2.5292e+00,  2.8507e+00, -8.9507e-01,  6.8477e+00,\n",
      "         -1.7049e-01, -5.8744e+00, -2.1839e+00, -5.5810e+00,  3.3013e+00],\n",
      "        [-8.7894e+00,  2.0955e+00, -5.5710e+00, -7.0135e+00,  4.8328e+00,\n",
      "         -1.9947e+00,  3.4964e+00,  3.5100e-01,  9.5108e-01,  6.9194e+00],\n",
      "        [ 8.4407e-01, -2.5671e+00,  3.7658e+00,  1.2973e+00,  7.9220e+00,\n",
      "         -1.2594e+00, -9.3886e+00, -2.7634e+00, -6.6832e+00,  1.7995e+00],\n",
      "        [-2.5915e+00,  6.4597e-01, -8.4103e+00, -6.9218e+00,  2.3604e+00,\n",
      "         -5.4211e+00,  1.1204e+01,  8.2955e-01, -9.6439e-01,  2.7523e+00],\n",
      "        [ 7.9551e+00,  8.6301e-01,  4.2536e+00,  1.0369e+00,  1.0929e-01,\n",
      "          3.4672e+00, -4.1762e+00, -3.3723e+00, -6.9665e+00, -5.2527e+00],\n",
      "        [-2.7239e+00,  2.8363e+00, -1.3946e+00, -3.8385e+00, -9.1325e-01,\n",
      "          8.4510e-01,  5.0836e+00,  1.7242e-01,  6.3750e-01, -1.7785e+00],\n",
      "        [ 1.7013e-01, -2.7666e+00,  2.4757e+00, -9.3563e-01,  6.8144e+00,\n",
      "         -1.0080e+00, -7.6056e+00, -2.8890e+00, -5.9767e+00,  3.2217e+00],\n",
      "        [ 1.0934e+01, -7.4708e-01,  3.8675e+00,  3.5235e+00, -1.7484e+00,\n",
      "          3.3520e+00, -3.5683e-01, -2.7006e+00, -8.7486e+00, -5.0729e+00],\n",
      "        [-1.6953e+00, -1.3474e+00, -1.5094e+00,  2.0125e+00, -1.4154e+00,\n",
      "         -1.2075e+00, -5.6271e-01, -5.4852e-01,  3.4271e+00, -1.3030e+00],\n",
      "        [-2.5268e-01, -4.6353e+00,  4.9804e+00,  4.9268e+00,  5.8784e+00,\n",
      "         -1.2653e+00, -1.2389e+01, -2.6152e+00,  6.1953e+00, -1.0327e+00],\n",
      "        [ 2.2492e+00, -1.6474e+00,  4.7916e+00,  5.9602e+00,  1.0899e+00,\n",
      "          1.2808e+00, -5.7934e+00, -4.7420e+00, -1.3850e+00, -2.2379e+00],\n",
      "        [-4.7826e+00, -1.3775e-01, -2.9430e+00, -8.1407e-01, -3.9199e-01,\n",
      "         -1.2852e+00,  1.2357e-01,  2.7285e+00,  1.5064e+00, -2.7213e-01],\n",
      "        [ 5.4608e+00, -3.9013e+00,  1.9036e+00,  8.2750e+00, -3.1918e+00,\n",
      "          1.2920e+00, -1.6464e+00, -2.8803e+00,  2.9064e-01, -9.3642e+00],\n",
      "        [ 1.4912e+00,  1.2103e+00,  5.0162e+00,  2.5086e+00,  2.9069e+00,\n",
      "          2.8262e+00, -4.9278e+00, -3.5405e+00, -4.1280e+00, -2.4107e+00],\n",
      "        [-1.5393e+00,  5.2922e+00,  7.3433e-01, -3.3635e+00,  2.6332e+00,\n",
      "          4.0868e+00, -9.0127e-01, -4.5037e+00, -5.5155e+00, -5.0961e-01],\n",
      "        [-9.0706e+00,  3.4321e+00, -5.1660e+00, -8.4292e+00,  3.1509e+00,\n",
      "         -9.0991e-01,  3.9464e+00, -8.8796e-01, -2.5287e+00,  4.7625e+00],\n",
      "        [ 2.5069e+00, -3.0323e+00,  1.2439e+01,  9.6031e+00,  6.8955e+00,\n",
      "          1.5744e+00, -1.1819e+01, -7.6660e+00, -4.0578e-01, -3.1931e+00],\n",
      "        [ 3.2704e-01, -7.6546e-01,  3.9796e-01,  1.3420e+00,  5.2858e-01,\n",
      "          5.3565e-01, -7.3574e-01, -8.0886e-01, -2.0586e-01,  6.5059e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(1,4):\n",
    "    val = iter(val_batch)\n",
    "    img_val,_ = next(val)\n",
    "    input_val = img_val.to(device = device)\n",
    "    img_val = img_val.squeeze()\n",
    "    model_ft.eval()\n",
    "    output = model_ft(input_val)\n",
    "    # ae_output = output.squeeze().cpu().detach().numpy()\n",
    "    # print(output)\n",
    "    # k = model_ft.forward_encoder(input)\n",
    "    # print(k.shape)\n",
    "\n",
    "    print(output)\n",
    "    plt.imshow(img_val[0])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "945a0cfe9be83e1d07d52518592eeae449cb339e6c04ecdfcf1a86b9d6be3856"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
