{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "load_path = 'checkpoint/model_final_HGD'\n",
    "\n",
    "from models.cnnmodel import Net\n",
    "from models.hgd_model2 import Generator\n",
    "from HandGestureDataset import HandGestureDataSet as HGD\n",
    "from utils import HGDThreshold as HGDT\n",
    "from utils import noise_sample\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Krishanu/Desktop/Education/Programcodes/Python/DeepLearning/Project/leapGestRecog/\"\n",
    "training = HGD(root = path, train = True,\n",
    "    transform = T.Compose([\n",
    "                T.ToPILImage(),\n",
    "              \n",
    "                # T.RandomHorizontalFlip(p=0.5),\n",
    "                T.Resize((240,240)),\n",
    "                # T.CenterCrop((190,180)),\n",
    "                T.RandomCrop((180,180)),\n",
    "                T.Resize((64,64)),\n",
    "                T.RandomRotation(20),\n",
    "                T.ToTensor(), \n",
    "                HGDT(55.0/256.0),\n",
    "                # T.Normalize(100/256.0,1),\n",
    "                # T.RandomAdjustSharpness(sharpness_factor = 4,p=0.5),\n",
    "                # T.RandomAutocontrast(p=1),\n",
    "\n",
    "                ])\n",
    "            )\n",
    "validation = HGD(root = path, train= False,\n",
    "    transform = T.Compose([\n",
    "                T.ToPILImage(),\n",
    "              \n",
    "                # T.RandomHorizontalFlip(p=0.5),\n",
    "                T.Resize((240,240)),\n",
    "                # T.CenterCrop((190,180)),\n",
    "                T.RandomCrop((180,180)),\n",
    "                T.Resize((64,64)),\n",
    "                T.RandomRotation(20),\n",
    "                T.ToTensor(), \n",
    "                HGDT(55.0/256.0),\n",
    "                # T.Normalize(100/256.0,1),\n",
    "                # T.RandomAdjustSharpness(sharpness_factor = 4,p=0.5),\n",
    "                # T.RandomAutocontrast(p=1),\n",
    "\n",
    "                ])\n",
    "            )\n",
    "\n",
    "batch_size = 32\n",
    "train_batch = DataLoader(training, batch_size=batch_size, shuffle=True, num_workers= 8)\n",
    "val_batch = DataLoader(validation, batch_size=batch_size, shuffle=True, num_workers= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = str(Path.home())+'/Documents/data/leapGestRecog/' #\n",
    "# data = HGD(root = path, train = True,\n",
    "#             transform = T.Compose([\n",
    "#                 T.ToPILImage(),\n",
    "#                 # T.CenterCrop(240),\n",
    "#                 T.Resize((64,64)),\n",
    "#                 T.ToTensor()\n",
    "#                 ]\n",
    "#             ))\n",
    "# # print(len(data))\n",
    "# training, validation = torch.utils.data.random_split(data, [16000,4000])\n",
    "# batch_size = 32\n",
    "# train_batch = DataLoader(training, batch_size=batch_size, shuffle=True, num_workers= 8)\n",
    "# val_batch = DataLoader(validation, batch_size=batch_size, shuffle=True, num_workers= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, training_data, device, optimizer, epoch, netG):\n",
    "\n",
    "    \"\"\"\n",
    "    This is the main function for training a deep neural network.\n",
    "    Inputs:\n",
    "    {\n",
    "    model: The Neural network\n",
    "    training_data: Training data with labels\n",
    "    device: Physical location of where data is stored (\"CPU\" or \"GPU\")\n",
    "    optimizer: Optimizer Function e.g. torch.optim.adam\n",
    "    scheduler: The type of scheduling for modifying the learning rate\n",
    "    num_epochs: number of iterations to train on the data\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    model.train() #Set the model to \"training\" mode and compute gradients\n",
    "    for batch_idx, (image, label) in enumerate(training_data):\n",
    "        image, label = image.to(device), label.to(device) # place the input data into gpu ram or cpu ram\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = nn.functional.cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            total_loss += loss.sum().item()\n",
    "            pred = output.argmax(dim =1 , keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(image), len(training_data.dataset),\n",
    "                100. * batch_idx / len(training_data), loss.item()))\n",
    "    print('-'*25)\n",
    "    print('training using Generator Data')\n",
    "    print('-'*25)\n",
    "    for i in range(batch_idx):\n",
    "        noise,idx,_,con = noise_sample(1,10,4,256,batch_size,device)\n",
    "        target = torch.LongTensor(idx).to(device)\n",
    "        image = netG(noise.squeeze((2,3)),target.view(-1,1),con)\n",
    "        label = torch.LongTensor(idx).to(device).squeeze(0)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = nn.functional.cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            total_loss += loss.sum().item()\n",
    "            pred = output.argmax(dim =1 , keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "        if i % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(image), len(training_data.dataset),\n",
    "                100. * i / len(training_data), loss.item()))\n",
    "    print('\\nTraining Set: \\n\\tAverage loss: {:.4f}\\n\\tAccuracy: {}/{} ({}%)'.format(\n",
    "        total_loss/len(training_data.dataset),\n",
    "        correct,\n",
    "        len(training_data.dataset),\n",
    "        100*correct/len(training_data.dataset)))\n",
    "    \n",
    "    # wandb.watch(model)\n",
    "    # wandb.log({'Training Loss':total_loss/len(training_data.dataset),'Training Accuracy':correct/len(training_data.dataset)},commit = False)\n",
    "\n",
    "\n",
    "\n",
    "def validate_model(model, test_data,scheduler, device):\n",
    "\n",
    "    \"\"\"\n",
    "    This is the function to monitor a deep neural network's performance on validation data. Sends images and predictions to wandb\n",
    "    \n",
    "    Inputs:\n",
    "    {\n",
    "    model: The Neural network\n",
    "    test_data: test data with labels\n",
    "    device: Physical location of where data is stored (CPU or GPU)\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval() #Set the model to \"evaluation\" mode and NOT compute gradients\n",
    "    total_loss = 0\n",
    "    correct = 0 \n",
    "    with torch.no_grad(): #Prevent pytorch from computing gradients\n",
    "        for image, label in test_data:\n",
    "            image, label = image.to(device), label.to(device) # place the input data into gpu ram or cpu ram\n",
    "            output = model(image)\n",
    "            total_loss = nn.functional.cross_entropy(output, label, reduction = 'sum').item()\n",
    "            pred = output.argmax(dim =1 , keepdim=True)\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "    total_loss /= len(test_data.dataset)\n",
    "    scheduler.step(total_loss)\n",
    "    print('Test set: \\n\\tAverage loss: {:.4f}\\n\\tAccuracy: {}/{} ({}%)\\n'.format(\n",
    "            total_loss,\n",
    "            correct, \n",
    "            len(test_data.dataset),\n",
    "            100. * correct / len(test_data.dataset)))\n",
    "    \n",
    "    \n",
    "    # wandb.log({'Validation Loss':total_loss,'Validation Accuracy':correct/len(test_data.dataset)},commit = False)\n",
    "            \n",
    "            \n",
    "    #######################################################################################################\n",
    "    # wandb_iter = iter(test_data)\n",
    "    # wandb_i,wandb_l = wandb_iter.next()\n",
    "    # with torch.no_grad():\n",
    "    #     wandb.log({'Predictions':[wandb.Image(wandb_i[i],caption = f\"Label: {int(wandb_l[i])}, Prediction: {int(torch.argmax(model(wandb_i[i].unsqueeze(0).to(device))))}\") for i in range(10)] },commit = True)\n",
    "    #######################################################################################################\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Determines if the model will be trained on gpu or cpu\n",
    "netG = Generator().to(device) #Initialize generator\n",
    "state_dict = torch.load(load_path)\n",
    "params = state_dict['params']\n",
    "netG.load_state_dict(state_dict['netG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "Learning Rate:  6e-05 \n",
      "Batch Size:  32\n",
      "cuda\n",
      "Train Epoch: 0 [0/16000 (0%)]\tLoss: 2.304056\n",
      "Train Epoch: 0 [3200/16000 (20%)]\tLoss: 2.119625\n",
      "Train Epoch: 0 [6400/16000 (40%)]\tLoss: 1.671628\n",
      "Train Epoch: 0 [9600/16000 (60%)]\tLoss: 1.521150\n",
      "Train Epoch: 0 [12800/16000 (80%)]\tLoss: 1.754311\n",
      "\n",
      "Training Set: \n",
      "\tAverage loss: 0.0570\n",
      "\tAccuracy: 5427/16000 (33.91875%)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\Krishanu\\Desktop\\Education\\Programcodes\\Python\\DeepLearning\\Project\\InfoGAN-PyTorch\\HandGestureDataset.py\", line 21, in __getitem__\n    image = read_image(self.data.iloc[idx]['Location'])\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torchvision\\io\\image.py\", line 258, in read_image\n    data = read_file(path)\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torchvision\\io\\image.py\", line 52, in read_file\n    data = torch.ops.image.read_file(path)\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\_ops.py\", line 502, in __call__\n    return self._op(*args, **kwargs or {})\nRuntimeError: Error opening input file\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     29\u001b[0m             train_model(model_ft,\n\u001b[0;32m     30\u001b[0m                         train_batch,\n\u001b[0;32m     31\u001b[0m                         device, \n\u001b[0;32m     32\u001b[0m                         optimizer_ft, \n\u001b[0;32m     33\u001b[0m                         epoch,netG)\n\u001b[1;32m---> 34\u001b[0m             validate_model(model_ft,\n\u001b[0;32m     35\u001b[0m                         val_batch,\n\u001b[0;32m     36\u001b[0m                         exp_lr_scheduler,\n\u001b[0;32m     37\u001b[0m                         device) \n\u001b[0;32m     38\u001b[0m \u001b[39m###################################                         \u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[39m#################################################\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m# wandb.finish()\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m#################################################\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 84\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, test_data, scheduler, device)\u001b[0m\n\u001b[0;32m     82\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \n\u001b[0;32m     83\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(): \u001b[39m#Prevent pytorch from computing gradients\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mfor\u001b[39;00m image, label \u001b[39min\u001b[39;00m test_data:\n\u001b[0;32m     85\u001b[0m         image, label \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device) \u001b[39m# place the input data into gpu ram or cpu ram\u001b[39;00m\n\u001b[0;32m     86\u001b[0m         output \u001b[39m=\u001b[39m model(image)\n",
      "File \u001b[1;32mc:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1345\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1346\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1372\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1373\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 3.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\Krishanu\\Desktop\\Education\\Programcodes\\Python\\DeepLearning\\Project\\InfoGAN-PyTorch\\HandGestureDataset.py\", line 21, in __getitem__\n    image = read_image(self.data.iloc[idx]['Location'])\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torchvision\\io\\image.py\", line 258, in read_image\n    data = read_file(path)\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torchvision\\io\\image.py\", line 52, in read_file\n    data = torch.ops.image.read_file(path)\n  File \"c:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\_ops.py\", line 502, in __call__\n    return self._op(*args, **kwargs or {})\nRuntimeError: Error opening input file\n"
     ]
    }
   ],
   "source": [
    "#################### WANDB Setup ###################\n",
    "# wandb.init(project = 'ECE6254'\n",
    "#         ,config = {'learning_rate':0.01, 'batch_size':64}\n",
    "#             )\n",
    "# config = wandb.config\n",
    "\n",
    "# batch_size_train = config.batch_size\n",
    "# batch_size_test = 1000\n",
    "# learning_rate = config.learning_rate\n",
    "####################################################\n",
    "\n",
    "\n",
    "\n",
    "##### Setup #####\n",
    "learning_rate = 6e-5\n",
    "num_epochs = 10 # Number of times to look over the data.\n",
    "model_ft = Net() # Initialize the model\n",
    "model_ft = model_ft.to(device) # Send the model to Ram or GPU Ram\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate, weight_decay = 7e-5) # Initialize optimizer\n",
    "exp_lr_scheduler = lr_sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft,patience=3,threshold=0.01) #initialize scheduler. Every (1) epoch, reduce the learning rate by a factor of 0.7\n",
    "#################\n",
    "\n",
    "print(len(train_batch.dataset))\n",
    "print(\"Learning Rate: \",learning_rate,\"\\nBatch Size: \", batch_size)\n",
    "print(device)\n",
    "\n",
    "##### Main Loop for Training ######\n",
    "for epoch in range(num_epochs):\n",
    "            train_model(model_ft,\n",
    "                        train_batch,\n",
    "                        device, \n",
    "                        optimizer_ft, \n",
    "                        epoch,netG)\n",
    "            validate_model(model_ft,\n",
    "                        train_batch,\n",
    "                        exp_lr_scheduler,\n",
    "                        device) \n",
    "###################################                         \n",
    "\n",
    "#################################################\n",
    "# wandb.finish()\n",
    "#################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'autoencoder_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# Determines if the model will be trained on gpu or cpu\u001b[39;00m\n\u001b[0;32m     19\u001b[0m model_ft \u001b[39m=\u001b[39m Net()\n\u001b[1;32m---> 20\u001b[0m model_ft\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mautoencoder_dict\u001b[39;49m\u001b[39m'\u001b[39;49m),strict \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m# Initialize the model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m# model_ft.encoder.requires_grad_(False)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m model_ft \u001b[39m=\u001b[39m model_ft\u001b[39m.\u001b[39mto(device) \u001b[39m# Send the model to Ram or GPU Ram\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Krishanu\\miniconda3\\envs\\dl_proj\\lib\\site-packages\\torch\\serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'autoencoder_dict'"
     ]
    }
   ],
   "source": [
    "#################### WANDB Setup ###################\n",
    "# wandb.init(project = 'ECE6254'\n",
    "#         ,config = {'learning_rate':0.01, 'batch_size':64}\n",
    "#             )\n",
    "# config = wandb.config\n",
    "\n",
    "# batch_size_train = config.batch_size\n",
    "# batch_size_test = 1000\n",
    "# learning_rate = config.learning_rate\n",
    "####################################################\n",
    "\n",
    "\n",
    "\n",
    "##### Setup #####\n",
    "\n",
    "learning_rate = 9e-5\n",
    "num_epochs = 10 # Number of times to look over the data.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Determines if the model will be trained on gpu or cpu\n",
    "model_ft = Net()\n",
    "model_ft.load_state_dict(torch.load('autoencoder_dict'),strict = False) # Initialize the model\n",
    "# model_ft.encoder.requires_grad_(False)\n",
    "model_ft = model_ft.to(device) # Send the model to Ram or GPU Ram\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate, weight_decay = 7e-4) # Initialize optimizer\n",
    "exp_lr_scheduler = lr_sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft,patience=3,threshold=0.01) #initialize scheduler. Every (1) epoch, reduce the learning rate by a factor of 0.7\n",
    "#################\n",
    "\n",
    "print(len(train_batch.dataset))\n",
    "print(\"Learning Rate: \",learning_rate,\"\\nBatch Size: \", batch_size)\n",
    "\n",
    "\n",
    "##### Main Loop for Training ######\n",
    "for epoch in range(num_epochs):\n",
    "            train_model(model_ft,\n",
    "                        train_batch,\n",
    "                        device, \n",
    "                        optimizer_ft, \n",
    "                        epoch)\n",
    "            validate_model(model_ft,\n",
    "                        val_batch,\n",
    "                        exp_lr_scheduler,\n",
    "                        device) \n",
    "###################################                         \n",
    "\n",
    "#################################################\n",
    "# wandb.finish()\n",
    "#################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(1,4):\n",
    "    val = iter(val_batch)\n",
    "    img_val,_ = next(val)\n",
    "    input_val = img_val.to(device = device)\n",
    "    img_val = img_val.squeeze()\n",
    "    model_ft.eval()\n",
    "    output = model_ft(input_val)\n",
    "    ae_output = output.squeeze().cpu().detach().numpy()\n",
    "    # print(output)\n",
    "    # k = model_ft.forward_encoder(input)\n",
    "    # print(k.shape)\n",
    "\n",
    "\n",
    "    plt.imshow(img_val[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = torch.load('autoencoder_dict')\n",
    "print(hello['decoder.7.weight'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "945a0cfe9be83e1d07d52518592eeae449cb339e6c04ecdfcf1a86b9d6be3856"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
